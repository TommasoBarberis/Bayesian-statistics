---
title: "Introduction to JAGS : birth weight"
output: 
  md_document:
    variant: "markdown_github"
# knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = "README.md" )})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

# 1. Context

We wish to compare the birth weight between boys and girls. To do this, we know the birth weight for a set of 48 children (file pnais48.txt). Column POIDNAIS represents birth weight, and column SEXE represents sex (0 : boy, 1 : girl). Variables are renamed as weight and sex. Moreover, for ease of use, the sex variable is re-encoded by adding 1 at each child (hence, the value 1 correspond to a boy, and 2 to a girl).

Hypothesysis: variability of the wight is the same between boys and girls.

```{r}
data_weight <- read.table("pnais48.txt", h = T, sep = ",")
sex <- data_weight$SEX + 1
weight <- data_weight$POIDNAIS
table(sex)
```

The study is on 29 boys and 19 girls.

The weight of children is supposed to follow a normal distribution, with different means between the two sexes ($\mu_b$ and $\mu_g$), but a shared standard deviation ($\sigma$). We set two priors: a uniform distribution between `2500` and `5000` grams for the mean weight for boys and girls and a uniform distribution between 200 and 800 grams for the standard deviation of the weight.

# 2. Model formalization

-   Set up the DAG associated to the model, specifying stochastic and deterministic links.

![](./assets/diag.png)

# 3. Implementation of the model

## Model

The model is implemented as a string, called `desc_model1`.

-   Beware: In ***JAGS***, the normal distribution is parameterized with the precision ($1/σ2 = τ$) and not the standard deviation. The birth weight of a child `i` follows a normal distribution (`dnorm`), centered on mean $\mu_i$ (dependent on sex), and with standard deviation $\sigma$ (or precision $τ$ under ***JAGS***).\
    Data is made of N = 48 cases: a loop is used to define the distribution followed by each of these observations.

-   For ease of use, the mean weights of boys and girls will be stored in a vector called `means`, of length 2. Hence, `mean[1]` will correspond to the mean weight of boys, and `mean[2]` to the mean weight of girls. For the `i` th child, `mean[sex[i]]` will give the mean weight expected for the child. The mean used for the distribution associated to each observation depends on the sex: `mean[2]` for girls and `mean[1]` for boys. The link between the mean used for the distribution associated to an observation and the sex is deterministic (simple equality, with no random part).

```{r}
library(rjags)

desc_model1 <-
  "
  model {
  
  # Defining links
  
  for (i in 1:Nchild)
{
    mu[i] <- mean[sex[i]]   # mean: vector of two elements, mean for boys                                and means for girls
    w[i] ~ dnorm(mu[i], tau) # weight
}

  # Definition for a prior distribution  
  mean[1] ~ dunif(2500, 5000) 
  mean[2] ~ dunif(2500, 5000)
  tau <- 1/sd # precision
  sd ~ dunif(200, 800)
  }
  "
```

**\~**: stochastic link

**\<-**: deterministic link

## Data

-   Define the data required for this model (data). Beware : Do no forget to include in the loop the number of observations (N).

```{r}
data_birth_w <- list(Nchild = length(data_weight$POIDNAIS),
             sex = sex,
             w = weight
             )
```

## Initial values

Start values need to be in the fixed interval of prior distribution:

```{r}
init_birth_w <- list(
  list(mean = c(2600, 4000), sd = 500),
  list(mean = c(4500, 2700), sd = 750),
  list(mean = c(4000, 4000), sd = 250))
```

## Implementation

```{r}
model_birth_w <- jags.model(file=textConnection(desc_model1),
                data = data_birth_w,
                inits = init_birth_w,
                n.chains = 3
                )

update(model_birth_w, 3000)
mcmc_birth_w <- coda.samples(model_birth_w, c("mean", "sd"), n.iter = 5000)
```

The table of chain `i` is obtained with the following command:

```{r}
# mcmc_birth_w[[1]]
```

Each table contains the parameter as columns, with the iterations of the ***MCMC*** as lines.

Computation of the posterior mean of the average birth weight of boys from the first ***MCMC***:

```{r}
mean(mcmc_birth_w[[1]][, "mean[1]"])
```

$\Rightarrow$ On this example, it is not possible to get an explicit description of the posterior distributions of the parameters. Yet, if $\sigma$ is known, $\mu_b$ and $\mu_g$ both follow a *normal* distribution. Likewise, if $\mu_b$ and $\mu_g$ are known, $\sigma$ follow as posterior an inverted *gamma* distribution.

But since neither parameter is known, the MCMC algorithm will proceed in an iterative way. From a starting value (given in `inits` parameter of the model) for $\sigma$, values of $\mu_b$ and $\mu_g$ are sampled in the conditional distribution given $\sigma$. Then a value of $\sigma$ is sample from its conditional distribution given the generated values of $\mu_b$ and $\mu_g$. This process is repeated a large number of times.

This process is a **Gibbs sampling**, which is a specialized case of the Metropolis algorithm. Gibbs sampling is relevant when the conditional distributions of the parameters are explicitly given.

# 4. Analysis of convergence and autocorrelation

## Convergence

$\Rightarrow$ Check visually the convergence form the track of the 3 runs of MCMC:

```{r}
plot(mcmc_birth_w)
```

Whatever the initial values of the parameters, the three chains seem to sample in similar ranges. The chains overlap, and mix well. This is a sign of convergence of the algorithm (convergence towards a distribution, and not a value).

```{r}
gelman.diag(mcmc_birth_w)
```

```{r}
gelman.plot(mcmc_birth_w)
```

The variance reduction index is 1 for the 3 parameters on all the 5000 kept iterations. This index is defined as:

$\sqrt{\frac{var(total)}{var(wthin-chains)}}$

It means that between-chains variance is negligible in front of within-chains variance, and so the three chains sample values from the same posterior distribution).\
The index of variance reduction has been close to 1 since the first iterations that have been kept. 3000 iterations burn-in time are enough here to reach convergence.

## Autocorrelation

$\Rightarrow$ Check the autocorrelation of values inside the chains:

```{r}
autocorr.plot(mcmc_birth_w)
```

Autocorrelation is weak or the three parameters. The autocorrelation is computed for each parameter and each chain.

```{r}
lapply(mcmc_birth_w, effectiveSize)
```

The efficiency size of the chains following the chains and parameter is between 2000 and 3000, not too different from the number of iterations per chain (5000).

```{r}
raftery.diag(mcmc_birth_w)
```

Raftery's diagnostic signals dependency factors close to 1, with a total N close to the 5000 realized iterations. We can conclude that is not necessary to perform more iterations.

## Number of sampled values

$\Rightarrow$ Check that are enough sampled values to predict correct posterior distributions of the parameters (`cumuplot`):

```{r}
cumuplot(mcmc_birth_w)
```

The estimates of means and quantiles at 2.5% and 97.5% seem stable after 2000 iterations for the 3 parameters. It means that are enough sampled values to describe the posterior distribution (perhaps a few more would be relevant for parameter $\sigma$). With this graph we cans also evaluate convergence.

# 5. Exploit the results

$\Rightarrow$ Represent joint posterior distribution of the parameters (function `pairs`).\
It is useful to concatenate the three chains to evaluate the *a posteriori* distribution (`as.data.frame.(as.matrix(.))`).

```{r}
mcmc_birth_w_tot <- as.data.frame(as.matrix(mcmc_birth_w))
pairs(mcmc_birth_w_tot)
```

Sampled values are a sample of the joint posterior distribution of the parameters. So, the covariance between the samples values of the parameters is an estimate of the real covariance between parameters. On this example, the correlation between the sampled values seems very weak, which shows absence of correlation between the parameters.

$\Rightarrow$ Compute a point estimate and a 95% - credibility interval of $\mu_b$ and $\mu_g$.

```{r}
summary(mcmc_birth_w)
```

Posterior mean and median are very close because the posterior distributions are symmetric. 95% - credibility intervals can be obtained from the 2.5% and 97.5% quantiles of the sampled values.

Girls: 3728.2 [3718.0, 3739]\
Boys: 3379.2 [3366.6, 3392]

$\Rightarrow$ Find out the above results "by hand", without using the function `summary` applied to MCMC. We have to compute the statistic on the sampled values on the three chains together.

```{r}
summary(mcmc_birth_w_tot)
```

```{r}
quantile(mcmc_birth_w_tot[, "mean[2]"], prob = c(0.025, 0.975))
```

```{r}
quantile(mcmc_birth_w_tot[, "mean[1]"], prob = c(0.025, 0.975))
```

```{r}
quantile(mcmc_birth_w_tot[, "sd"], prob = c(0.025, 0.975))
```

```{r}
apply(mcmc_birth_w_tot, 2, quantile, prob = c(0.025, 0.975))
```

$\Rightarrow$ Compute the probability that the mean weight of boys is larger than the mean weight of girls.

An estimate of this probability can be calculated as the proportion, among the couples of parameters sampled in the posterior distribution, of the couples wheres the boys' mean weight is larger than the girls' mean weight.\
Graphically, it can be seen as the proportion of iterations for wichh the couple ($\mu_b$, $\mu_g$) is over the diagonal.

```{r}
sum(mcmc_birth_w_tot[, "mean[1]"] > mcmc_birth_w_tot[, "mean[2]"])/nrow(mcmc_birth_w_tot)
```

The probability that the boys' mean weight is larger than the girls' mean weight is very high.

# 6. Evolution of the model

Children weight is positive. This constraint is not in the model, since a normal distribution also cover negative values. A solutions is to truncate the distribution of weights at 0. In **JAGS**, the truncature operator is `T(a, b) : a` is the low troncature, `b`, the high truncature (leaving it empty if we do not want truncature on a side).

$\Rightarrow$ Build a new model with this constraint, and compare the results with those of the first model.

```{r}
desc_model_birth_w2 <- 
"model {
  for (i in 1:Nchild) {
    w[i] ~ dnorm(mu[i], tau)T(0, )
    mu[i] <- mean[sex[i]]
  }
  mean[1] ~ dunif(2500, 5000)
  mean[2] ~ dunif(2500, 5000)
  tau <- 1/(sd^2)
  sd ~ dunif(200, 800)
}"
```

```{r}
model_birth_w2 <- jags.model(textConnection(desc_model_birth_w2), 
                             data = data_birth_w, 
                             inits = init_birth_w, 
                             n.chains = 3)
update(model_birth_w2, 3000)
mcmc_birth_w2 <- coda.samples(model_birth_w2, variable.names = c("mean[1]", "mean[2]", "sd"), n.iter = 5000)
```

```{r}
summary(mcmc_birth_w2)
```

The results do not change. Indeed, considering the standard deviation of the first model, the probability to get negative weight is quasi-null. Likewise, we could have constrained the prior distribution on $\mu_b$ and $\mu_g$ to be positive, but it would not have any impact on the results in this example, since the *a posteriori* distributions are totally negatives values.
